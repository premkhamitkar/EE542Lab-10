{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import hashlib\n",
    "import os \n",
    "from utils import logger\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from utils import logger\n",
    "#def lassoSelection(X,y,)\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "def scores_for_ks(test_labels, knn_labels, ks):\n",
    "    #f1_weight = []\n",
    "    #f1_macro = []\n",
    "    #f1_micro = []\n",
    "    f1 = []\n",
    "    acc = []\n",
    "    for k in ks:\n",
    "        pred_k = stats.mode(knn_labels[:,:k], axis=1)[0].reshape((-1,))\n",
    "        print(pred_k)\n",
    "        #f1_weight.append(f1_score(test_labels, pred_k, average='weighted'))\n",
    "        #f1_macro.append(f1_score(test_labels, pred_k, average='macro'))\n",
    "        f1.append(f1_score(test_labels, pred_k))\n",
    "        acc.append(accuracy_score(test_labels, pred_k))\n",
    "    return {'f1': f1, 'accuracy': acc, }\n",
    "\n",
    "def plot_prediction_quality(scores, ks):\n",
    "    colors = ['r-', 'b-', 'g-','y-'][:len(scores)]\n",
    "    for (k,v), color in zip(scores.items(), colors):\n",
    "        plt.plot(ks, v, color, label=k)\n",
    "    plt.legend()\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('prediction quality')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_quality(predictor, test_features, test_labels, model_name, verbose=True, num_batches=1):\n",
    "    \"\"\"\n",
    "    Evaluate quality metrics of a model on a test set. \n",
    "    \"\"\"\n",
    "    # tune the predictor to provide the verbose response\n",
    "    predictor.accept = 'application/json; verbose=true'\n",
    "    \n",
    "    # split the test data set into num_batches batches and evaluate using prediction endpoint. \n",
    "    print('running prediction (quality)...')\n",
    "    batches = np.array_split(test_features, num_batches)\n",
    "    knn_labels = []\n",
    "    for batch in batches:\n",
    "        pred_result = predictor.predict(batch)\n",
    "        cur_knn_labels = np.array([pred_result['predictions'][i]['labels'] for i in range(len(pred_result['predictions']))])\n",
    "        knn_labels.append(cur_knn_labels)\n",
    "    knn_labels = np.concatenate(knn_labels)\n",
    "    print('running prediction (quality)... done')\n",
    "    print(knn_labels)\n",
    "    print(test_labels)\n",
    "    # figure out different k values\n",
    "    top_k = knn_labels.shape[1]\n",
    "    ks = range(1, top_k+1)\n",
    "    \n",
    "    # compute scores for the quality of the model for each value of k\n",
    "    print('computing scores for all values of k... ')\n",
    "    quality_scores = scores_for_ks(test_labels, knn_labels, ks)\n",
    "    print('computing scores for all values of k... done')\n",
    "    if verbose:\n",
    "        plot_prediction_quality(quality_scores, ks)\n",
    "    \n",
    "    return quality_scores\n",
    "\n",
    "def evaluate_latency(predictor, test_features, test_labels, model_name, verbose=True, num_batches=1):\n",
    "    \"\"\"\n",
    "    Evaluate the run-time of a model on a test set.\n",
    "    \"\"\"\n",
    "    # tune the predictor to provide the non-verbose response\n",
    "    predictor.accept = 'application/json'\n",
    "    \n",
    "    # latency for large batches:\n",
    "    # split the test data set into num_batches batches and evaluate the latencies of the calls to endpoint. \n",
    "    print('running prediction (latency)...')\n",
    "    batches = np.array_split(test_features, num_batches)\n",
    "    test_preds = []\n",
    "    latency_sum = 0\n",
    "    for batch in batches:\n",
    "        start = time.time()\n",
    "        pred_batch = predictor.predict(batch)\n",
    "        latency_sum += time.time() - start\n",
    "    latency_mean = latency_sum / float(num_batches)\n",
    "    avg_batch_size = test_features.shape[0] / num_batches\n",
    "    \n",
    "    # estimate the latency for a batch of size 1\n",
    "    latencies = []\n",
    "    attempts = 128\n",
    "    for i in range(attempts):\n",
    "        start = time.time()\n",
    "        pred_batch = predictor.predict(test_features[i].reshape((1,-1)))\n",
    "        latencies.append(time.time() - start)\n",
    "\n",
    "    latencies = sorted(latencies)\n",
    "    latency1_mean = sum(latencies) / float(attempts)\n",
    "    latency1_p90 = latencies[int(attempts*0.9)]\n",
    "    latency1_p99 = latencies[int(attempts*0.99)]\n",
    "    print('running prediction (latency)... done')\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"{:<11} {:.3f}\".format('Latency (ms, batch size %d):' % avg_batch_size, latency_mean * 1000))\n",
    "        print(\"{:<11} {:.3f}\".format('Latency (ms) mean for single item:', latency1_mean * 1000))\n",
    "        print(\"{:<11} {:.3f}\".format('Latency (ms) p90 for single item:', latency1_p90 * 1000))\n",
    "        print(\"{:<11} {:.3f}\".format('Latency (ms) p99 for single item:', latency1_p99 * 1000))\n",
    "        \n",
    "    return {'Latency': latency_mean, 'Latency1_mean': latency1_mean, 'Latency1_p90': latency1_p90, \n",
    "            'Latency1_p99': latency1_p99}\n",
    "\n",
    "def evaluate(predictor, test_features, test_labels, model_name, verbose=True, num_batches=100):\n",
    "    eval_result_q = evaluate_quality(pred, test_features, test_labels, model_name=model_name, verbose=verbose, num_batches=num_batches)\n",
    "    eval_result_l = evaluate_latency(pred, test_features, test_labels, model_name=model_name, verbose=verbose, num_batches=num_batches)\n",
    "    return dict(list(eval_result_q.items()) + list(eval_result_l.items()))\n",
    "\n",
    "def lassoSelection(X_train, y_train, n):\n",
    "    '''\n",
    "    Lasso feature selection.  Select n features. \n",
    "    '''\n",
    "    #lasso feature selection\n",
    "    #print (X_train)\n",
    "    clf = LassoCV()\n",
    "    sfm = SelectFromModel(clf, threshold=0)\n",
    "    sfm.fit(X_train, y_train)\n",
    "    X_transform = sfm.transform(X_train)\n",
    "    n_features = X_transform.shape[1]\n",
    "    \n",
    "    #print(n_features)\n",
    "    while n_features > n:\n",
    "        sfm.threshold += 0.01\n",
    "        X_transform = sfm.transform(X_train)\n",
    "        n_features = X_transform.shape[1]\n",
    "    features = [index for index,value in enumerate(sfm.get_support()) if value == True  ]\n",
    "    logger.info(\"selected features are {}\".format(features))\n",
    "    return features\n",
    "\n",
    "\n",
    "def specificity_score(y_true, y_predict):\n",
    "    '''\n",
    "    true_negative rate\n",
    "    '''\n",
    "    true_negative = len([index for index,pair in enumerate(zip(y_true,y_predict)) if pair[0]==pair[1] and pair[0]==0 ])\n",
    "    real_negative = len(y_true) - sum(y_true)\n",
    "    return true_negative / real_negative \n",
    "\n",
    "def delete_endpoint(predictor):\n",
    "    try:\n",
    "        boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "        print('Deleted {}'.format(predictor.endpoint))\n",
    "    except:\n",
    "        print('Already deleted: {}'.format(predictor.endpoint))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trained_estimator_from_hyperparams(s3_train_data, hyperparams, output_path, s3_test_data=None):\n",
    "    \"\"\"\n",
    "    Create an Estimator from the given hyperparams, fit to training data, \n",
    "    and return a deployed predictor\n",
    "    \n",
    "    \"\"\"\n",
    "    # specify algorithm containers. These contain the code for the training job\n",
    "    containers = {\n",
    "        'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/knn:1',\n",
    "        'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/knn:1',\n",
    "        'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/knn:1',\n",
    "        'eu-west-1': '438346466558.dkr.ecr.eu-west-1.amazonaws.com/knn:1',\n",
    "        'ap-northeast-1': '351501993468.dkr.ecr.ap-northeast-1.amazonaws.com/knn:1',\n",
    "        'ap-northeast-2': '835164637446.dkr.ecr.ap-northeast-2.amazonaws.com/knn:1',\n",
    "        'ap-southeast-2': '712309505854.dkr.ecr.ap-southeast-2.amazonaws.com/knn:1'\n",
    "    }\n",
    "    # set up the estimator\n",
    "    knn = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],\n",
    "        get_execution_role(),\n",
    "        train_instance_count=1,\n",
    "        train_instance_type='ml.m5.2xlarge',\n",
    "        output_path=output_path,\n",
    "        sagemaker_session=sagemaker.Session())\n",
    "    knn.set_hyperparameters(**hyperparams)\n",
    "    \n",
    "    # train a model. fit_input contains the locations of the train and test data\n",
    "    fit_input = {'train': s3_train_data}\n",
    "    if s3_test_data is not None:\n",
    "        fit_input['test'] = s3_test_data\n",
    "    knn.fit(fit_input)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_from_hyperparams(knn_estimator, estimator_name, instance_type, endpoint_name=None): \n",
    "    knn_predictor = knn_estimator.deploy(initial_instance_count=1, instance_type=instance_type,\n",
    "                                        endpoint_name=endpoint_name)\n",
    "    knn_predictor.content_type = 'text/csv'\n",
    "    knn_predictor.serializer = csv_serializer\n",
    "    knn_predictor.deserializer = json_deserializer\n",
    "    return knn_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_apx_max(row):\n",
    "    '''\n",
    "    highlight the aproximate best (max or min) in a Series yellow.\n",
    "    '''\n",
    "    max_val = row.max()\n",
    "    colors = ['background-color: yellow' if cur_val >= max_val * 0.9975 else '' for cur_val in row]\n",
    "        \n",
    "    return colors\n",
    "def highlight_far_from_min(row):\n",
    "    '''\n",
    "    highlight the aproximate best (max or min) in a Series yellow.\n",
    "    '''\n",
    "    med_val = row.median()\n",
    "    colors = ['background-color: red' if cur_val >= med_val * 1.2 else '' for cur_val in row]\n",
    "        \n",
    "    return colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    data_dir =\"data/\"\n",
    "\n",
    "    data_file = data_dir + \"miRNA_matrix.csv\"\n",
    "\n",
    "    df = pd.read_csv(data_file)\n",
    "    # print(df)\n",
    "    y_data = df.pop('label').values\n",
    "\n",
    "    df.pop('file_id')\n",
    "\n",
    "    columns =df.columns\n",
    "    #print (columns)\n",
    "    X_data = df.values\n",
    "\n",
    "    # split the data to train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=0)\n",
    "    \n",
    "\n",
    "    #standardize the data.\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # check the distribution of tumor and normal sampels in traing and test data set.\n",
    "    logger.info(\"Percentage of tumor cases in training set is {}\".format(sum(y_train)/len(y_train)))\n",
    "    logger.info(\"Percentage of tumor cases in test set is {}\".format(sum(y_test)/len(y_test)))\n",
    "    \n",
    "    n = 7\n",
    "    features_columns = lassoSelection(X_train, y_train, n)\n",
    "    \n",
    "    \n",
    "    import io\n",
    "    import sagemaker.amazon.common as smac\n",
    "    import boto3\n",
    "    import sagemaker  \n",
    "    from sagemaker import get_execution_role\n",
    "    from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "    bucket =  \"cancer-bucket\"\n",
    "    prefix = 'knn-prediction'\n",
    "    key = 'cancer-data'\n",
    "    \n",
    "    #write the train data to S3\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_numpy_to_dense_tensor(buf, X_train[:,features_columns], y_train)\n",
    "    buf.seek(0)   \n",
    "    boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "    s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)    \n",
    "    print('uploaded training data location: {}'.format(s3_train_data)) \n",
    "    print(X_train[:,features_columns].shape)\n",
    "\n",
    "    #write the test data to S3\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_numpy_to_dense_tensor(buf, X_test[:,features_columns], y_test)\n",
    "    buf.seek(0)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test', key)).upload_fileobj(buf)\n",
    "    s3_test_data = 's3://{}/{}/test/{}'.format(bucket, prefix, key)\n",
    "    print('uploaded test data location: {}'.format(s3_test_data))    \n",
    "    print(X_test[:,features_columns].shape)\n",
    "    \n",
    "    #scores = model_fit_predict(X_train[:,feaures_columns],X_test[:,feaures_columns],y_train,y_test)\n",
    "\n",
    "    #draw(scores)\n",
    "    #lasso cross validation\n",
    "    # lassoreg = Lasso(random_state=0)\n",
    "    # alphas = np.logspace(-4, -0.5, 30)\n",
    "    # tuned_parameters = [{'alpha': alphas}]\n",
    "    # n_fold = 10\n",
    "    # clf = GridSearchCV(lassoreg,tuned_parameters,cv=10, refit = False)\n",
    "    # clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: knn-2018-09-20-07-28-26-874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'index_metric': u'L2', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'_log_level': u'info', u'faiss_index_ivf_nlists': u'auto', u'epochs': u'1', u'index_type': u'faiss.Flat', u'_faiss_index_nprobe': u'5', u'_kvstore': u'dist_async', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000'}\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'sample_size': u'297', u'feature_dim': u'5', u'k': u'100', u'predictor_type': u'classifier'}\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] Final configuration: {u'index_metric': u'L2', u'predictor_type': u'classifier', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'_log_level': u'info', u'feature_dim': u'5', u'faiss_index_ivf_nlists': u'auto', u'sample_size': u'297', u'epochs': u'1', u'index_type': u'faiss.Flat', u'_faiss_index_nprobe': u'5', u'_kvstore': u'dist_async', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'k': u'100'}\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 WARNING 139704133199680] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/f1a01daf-fa08-45d9-a5cb-c900bd8e9062', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'HOSTNAME': 'aws', 'AWS_REGION': 'us-west-2', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/e4663268-c2c0-4e89-86f6-b338345232f5', 'OMP_NUM_THREADS': '4', 'PWD': '/', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'TRAINING_JOB_NAME': 'knn-2018-09-20-07-28-26-874', 'ENVROOT': '/opt/amazon', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'LD_LIBRARY_PATH': '/opt/amazon/lib:/usr/local/nvidia/lib64:/opt/amazon/lib/stubs'}\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/f1a01daf-fa08-45d9-a5cb-c900bd8e9062', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'HOME': '/root', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'LD_LIBRARY_PATH': '/opt/amazon/lib:/usr/local/nvidia/lib64:/opt/amazon/lib/stubs', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.4', 'HOSTNAME': 'aws', 'AWS_REGION': 'us-west-2', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/e4663268-c2c0-4e89-86f6-b338345232f5', 'DMLC_ROLE': 'scheduler', 'OMP_NUM_THREADS': '4', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_NAME': 'knn-2018-09-20-07-28-26-874', 'DMLC_PS_ROOT_PORT': '9000'}\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] Launching parameter server for role server\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/f1a01daf-fa08-45d9-a5cb-c900bd8e9062', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'HOSTNAME': 'aws', 'AWS_REGION': 'us-west-2', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/e4663268-c2c0-4e89-86f6-b338345232f5', 'OMP_NUM_THREADS': '4', 'PWD': '/', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'TRAINING_JOB_NAME': 'knn-2018-09-20-07-28-26-874', 'ENVROOT': '/opt/amazon', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'LD_LIBRARY_PATH': '/opt/amazon/lib:/usr/local/nvidia/lib64:/opt/amazon/lib/stubs'}\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/f1a01daf-fa08-45d9-a5cb-c900bd8e9062', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'HOME': '/root', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'LD_LIBRARY_PATH': '/opt/amazon/lib:/usr/local/nvidia/lib64:/opt/amazon/lib/stubs', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.4', 'HOSTNAME': 'aws', 'AWS_REGION': 'us-west-2', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/e4663268-c2c0-4e89-86f6-b338345232f5', 'DMLC_ROLE': 'server', 'OMP_NUM_THREADS': '4', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_NAME': 'knn-2018-09-20-07-28-26-874', 'DMLC_PS_ROOT_PORT': '9000'}\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/f1a01daf-fa08-45d9-a5cb-c900bd8e9062', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib:/usr/local/nvidia/lib64:/opt/amazon/lib/stubs', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'ethwe', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.32.0.4', 'AWS_REGION': 'us-west-2', 'TRAINING_JOB_NAME': 'knn-2018-09-20-07-28-26-874', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'OMP_NUM_THREADS': '4', 'HOSTNAME': 'aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/e4663268-c2c0-4e89-86f6-b338345232f5', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1'}\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] Using default worker.\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] nvidia-smi took: 0.0251338481903 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] Create Store: dist_async\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 ERROR 139704133199680] nvidia-smi: failed to run (127): /bin/sh: nvidia-smi: command not found\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:07 INFO 139704133199680] Using per-worker sample size = 297 (Available virtual memory = 31133888512 bytes, GPU free memory = 0 bytes, number of workers = 1). If an out-of-memory error occurs, choose a larger instance type, use dimension reduction, decrease sample_size, and/or decrease mini_batch_size.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1537428668.007173, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KNN\"}, \"StartTime\": 1537428668.007123}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:08 INFO 139704133199680] push reservoir to kv... 1 num_workers 0 rank\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:08 INFO 139704133199680] ...done (297)\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:08 INFO 139704133199680] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 297, \"sum\": 297.0, \"min\": 297}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 297, \"sum\": 297.0, \"min\": 297}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 297, \"sum\": 297.0, \"min\": 297}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1537428668.024655, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KNN\", \"epoch\": 0}, \"StartTime\": 1537428668.00743}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:08 INFO 139704133199680] #throughput_metric: host=algo-1, train throughput=17141.7523909 records/second\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:08 INFO 139704133199680] pulled row count... worker 0 rows 297\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:08 INFO 139704133199680] pulled... worker 0 data (297, 5) labels (297, 1) nans 0\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:08 INFO 139704133199680] calling index.train...\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:08 INFO 139704133199680] ...done calling index.train\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:08 INFO 139704133199680] calling index.add...\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:08 INFO 139704133199680] ...done calling index.add\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.6570816040039062, \"sum\": 0.6570816040039062, \"min\": 0.6570816040039062}, \"finalize.time\": {\"count\": 1, \"max\": 1.9500255584716797, \"sum\": 1.9500255584716797, \"min\": 1.9500255584716797}, \"initialize.time\": {\"count\": 1, \"max\": 679.8439025878906, \"sum\": 679.8439025878906, \"min\": 679.8439025878906}, \"update.time\": {\"count\": 1, \"max\": 17.045021057128906, \"sum\": 17.045021057128906, \"min\": 17.045021057128906}}, \"EndTime\": 1537428668.027521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KNN\"}, \"StartTime\": 1537428667.270423}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 128, \"sum\": 128.0, \"min\": 128}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 128, \"sum\": 128.0, \"min\": 128}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 128, \"sum\": 128.0, \"min\": 128}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1537428668.042503, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KNN\"}, \"StartTime\": 1537428668.027983}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:08 INFO 139704133199680] #test_score (algo-1) : ('accuracy', 0.8984375)\u001b[0m\n",
      "\u001b[31m[09/20/2018 07:31:08 INFO 139704133199680] #quality_metric: host=algo-1, test accuracy <score>=0.8984375\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 958.3439826965332, \"sum\": 958.3439826965332, \"min\": 958.3439826965332}, \"setuptime\": {\"count\": 1, \"max\": 19.242048263549805, \"sum\": 19.242048263549805, \"min\": 19.242048263549805}}, \"EndTime\": 1537428668.046104, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KNN\"}, \"StartTime\": 1537428668.027581}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Billable seconds: 39\n"
     ]
    }
   ],
   "source": [
    "hyperparams_flat_l2 = {\n",
    "    'feature_dim': 5,\n",
    "    'k': 100,\n",
    "    'sample_size': 297,\n",
    "    'predictor_type': 'classifier' \n",
    "    # NOTE: The default distance is L2 and index is Flat, so we don't list them here\n",
    "}\n",
    "output_path_flat_l2 = 's3://' + bucket + '/' + prefix + '/flat_l2/output'\n",
    "knn_estimator_flat_l2 = trained_estimator_from_hyperparams(s3_train_data, hyperparams_flat_l2, output_path_flat_l2, \n",
    "                                                           s3_test_data=s3_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: knn-2018-09-20-10-18-42-354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "setting up endpoint for instance_type=ml.m4.xlarge, index_type=flat_l2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint with name knn-latency-flat-l2-ml-m4-xlarge-1537438722-2494462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "instance_types = ['ml.m4.xlarge']\n",
    "index2estimator = {'flat_l2': knn_estimator_flat_l2}\n",
    "\n",
    "eval_results = {}\n",
    "\n",
    "for index in index2estimator:\n",
    "    estimator = index2estimator[index]\n",
    "    eval_results[index] = {}\n",
    "    for instance_type in instance_types:\n",
    "        model_name = 'knn_%s_%s'%(index, instance_type)\n",
    "        endpoint_name = 'knn-latency-%s-%s-%s'%(index.replace('_','-'), instance_type.replace('.','-'),\n",
    "                                               str(time.time()).replace('.','-'))\n",
    "        print('\\nsetting up endpoint for instance_type=%s, index_type=%s' %(instance_type, index))\n",
    "        pred = predictor_from_hyperparams(estimator, index, instance_type, endpoint_name=endpoint_name)\n",
    "        print('')\n",
    "        eval_result = evaluate(pred,X_test[:,features_columns], y_test, model_name=model_name, verbose=True)        \n",
    "        eval_result['instance'] = instance_type \n",
    "        eval_result['index'] = index \n",
    "        eval_results[index][instance_type] = eval_result\n",
    "        delete_endpoint(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flat_12': {'ml.m4.xlarge': {'f1': [0.9781659388646288, 0.9823008849557522, 0.9785407725321889, 0.9870129870129869, 0.9785407725321889, 0.9785407725321889, 0.9743589743589743, 0.9699570815450643, 0.9743589743589743, 0.9699570815450643, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9661016949152543, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9579831932773111, 0.9579831932773111, 0.9623430962343097, 0.9623430962343097, 0.9623430962343097, 0.9623430962343097, 0.9623430962343097, 0.9623430962343097, 0.9583333333333334, 0.9583333333333334, 0.9543568464730291, 0.9543568464730291, 0.9504132231404958, 0.9504132231404958, 0.9504132231404958, 0.9504132231404958, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687], 'accuracy': [0.9609375, 0.96875, 0.9609375, 0.9765625, 0.9609375, 0.9609375, 0.953125, 0.9453125, 0.953125, 0.9453125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9375, 0.9453125, 0.9453125, 0.9453125, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.921875, 0.921875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.921875, 0.921875, 0.9140625, 0.9140625, 0.90625, 0.90625, 0.90625, 0.90625, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375], 'Latency': 0.006782610416412354, 'Latency1_mean': 0.007119670510292053, 'Latency1_p90': 0.00830221176147461, 'Latency1_p99': 0.01297616958618164}}}\n",
      "flat_12\n",
      "{'ml.m4.xlarge': {'f1': [0.9781659388646288, 0.9823008849557522, 0.9785407725321889, 0.9870129870129869, 0.9785407725321889, 0.9785407725321889, 0.9743589743589743, 0.9699570815450643, 0.9743589743589743, 0.9699570815450643, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9661016949152543, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9579831932773111, 0.9579831932773111, 0.9623430962343097, 0.9623430962343097, 0.9623430962343097, 0.9623430962343097, 0.9623430962343097, 0.9623430962343097, 0.9583333333333334, 0.9583333333333334, 0.9543568464730291, 0.9543568464730291, 0.9504132231404958, 0.9504132231404958, 0.9504132231404958, 0.9504132231404958, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687], 'accuracy': [0.9609375, 0.96875, 0.9609375, 0.9765625, 0.9609375, 0.9609375, 0.953125, 0.9453125, 0.953125, 0.9453125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9375, 0.9453125, 0.9453125, 0.9453125, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.921875, 0.921875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.921875, 0.921875, 0.9140625, 0.9140625, 0.90625, 0.90625, 0.90625, 0.90625, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375], 'Latency': 0.006782610416412354, 'Latency1_mean': 0.007119670510292053, 'Latency1_p90': 0.00830221176147461, 'Latency1_p99': 0.01297616958618164}}\n",
      "ml.m4.xlarge\n",
      "{'f1': [0.9781659388646288, 0.9823008849557522, 0.9785407725321889, 0.9870129870129869, 0.9785407725321889, 0.9785407725321889, 0.9743589743589743, 0.9699570815450643, 0.9743589743589743, 0.9699570815450643, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9743589743589743, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9661016949152543, 0.9702127659574469, 0.9702127659574469, 0.9702127659574469, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9661016949152543, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9620253164556962, 0.9579831932773111, 0.9579831932773111, 0.9623430962343097, 0.9623430962343097, 0.9623430962343097, 0.9623430962343097, 0.9623430962343097, 0.9623430962343097, 0.9583333333333334, 0.9583333333333334, 0.9543568464730291, 0.9543568464730291, 0.9504132231404958, 0.9504132231404958, 0.9504132231404958, 0.9504132231404958, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687, 0.9465020576131687], 'accuracy': [0.9609375, 0.96875, 0.9609375, 0.9765625, 0.9609375, 0.9609375, 0.953125, 0.9453125, 0.953125, 0.9453125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9375, 0.9453125, 0.9453125, 0.9453125, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.921875, 0.921875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.921875, 0.921875, 0.9140625, 0.9140625, 0.90625, 0.90625, 0.90625, 0.90625, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375], 'Latency': 0.006782610416412354, 'Latency1_mean': 0.007119670510292053, 'Latency1_p90': 0.00830221176147461, 'Latency1_p99': 0.01297616958618164}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col3 {\n",
       "            background-color:  yellow;\n",
       "        }</style>  \n",
       "<table id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >acc_1</th> \n",
       "        <th class=\"col_heading level0 col1\" >acc_2</th> \n",
       "        <th class=\"col_heading level0 col2\" >acc_3</th> \n",
       "        <th class=\"col_heading level0 col3\" >acc_4</th> \n",
       "        <th class=\"col_heading level0 col4\" >acc_5</th> \n",
       "        <th class=\"col_heading level0 col5\" >acc_6</th> \n",
       "        <th class=\"col_heading level0 col6\" >acc_7</th> \n",
       "        <th class=\"col_heading level0 col7\" >acc_8</th> \n",
       "        <th class=\"col_heading level0 col8\" >acc_9</th> \n",
       "        <th class=\"col_heading level0 col9\" >acc_10</th> \n",
       "        <th class=\"col_heading level0 col10\" >acc_11</th> \n",
       "        <th class=\"col_heading level0 col11\" >acc_12</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0level0_row0\" class=\"row_heading level0 row0\" >flat_12_ml.m4.xlarge</th> \n",
       "        <td id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col0\" class=\"data row0 col0\" >96.1</td> \n",
       "        <td id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col1\" class=\"data row0 col1\" >96.9</td> \n",
       "        <td id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col2\" class=\"data row0 col2\" >96.1</td> \n",
       "        <td id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col3\" class=\"data row0 col3\" >97.7</td> \n",
       "        <td id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col4\" class=\"data row0 col4\" >96.1</td> \n",
       "        <td id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col5\" class=\"data row0 col5\" >96.1</td> \n",
       "        <td id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col6\" class=\"data row0 col6\" >95.3</td> \n",
       "        <td id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col7\" class=\"data row0 col7\" >94.5</td> \n",
       "        <td id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col8\" class=\"data row0 col8\" >95.3</td> \n",
       "        <td id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col9\" class=\"data row0 col9\" >94.5</td> \n",
       "        <td id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col10\" class=\"data row0 col10\" >95.3</td> \n",
       "        <td id=\"T_7a2ae4a2_bcbe_11e8_aefe_7933d9accfd0row0_col11\" class=\"data row0 col11\" >95.3</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbb9d9ff748>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "k_range = range(1, 13)\n",
    "df_index = []\n",
    "data = []\n",
    "columns_lat = ['latency_mean', 'latency1_mean', 'latency1_p90', 'latency1_p99']\n",
    "columns_acc = ['acc_%d' % k for k in k_range]\n",
    "columns = columns_lat + columns_acc\n",
    "#print(eval_result)\n",
    "print (eval_results)\n",
    "for index, index_res in eval_results.items():\n",
    "    print (index)\n",
    "    print (index_res)\n",
    "    for instance, res in index_res.items():\n",
    "        # for sample size?\n",
    "        print(instance)\n",
    "        print(res)\n",
    "        df_index.append(index+'_'+instance)\n",
    "        latencies = np.array([res['Latency'], res['Latency1_mean'], res['Latency1_p90'], res['Latency1_p99']])\n",
    "        row = np.concatenate([latencies*10,\n",
    "                             res['accuracy'][k_range[0] - 1:k_range[-1] ]])\n",
    "        row *= 100\n",
    "        data.append(row)\n",
    "\n",
    "df = pd.DataFrame(index=df_index, data=data, columns=columns)\n",
    "df_acc = df[columns_acc]\n",
    "df_lat = df[columns_lat]\n",
    "\n",
    "\n",
    "df_acc.round(decimals=1).style.apply(highlight_apx_max, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_7d8b74a4_bcbe_11e8_aefe_7933d9accfd0\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >latency_mean</th> \n",
       "        <th class=\"col_heading level0 col1\" >latency1_mean</th> \n",
       "        <th class=\"col_heading level0 col2\" >latency1_p90</th> \n",
       "        <th class=\"col_heading level0 col3\" >latency1_p99</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_7d8b74a4_bcbe_11e8_aefe_7933d9accfd0level0_row0\" class=\"row_heading level0 row0\" >flat_12_ml.m4.xlarge</th> \n",
       "        <td id=\"T_7d8b74a4_bcbe_11e8_aefe_7933d9accfd0row0_col0\" class=\"data row0 col0\" >6.8</td> \n",
       "        <td id=\"T_7d8b74a4_bcbe_11e8_aefe_7933d9accfd0row0_col1\" class=\"data row0 col1\" >7.1</td> \n",
       "        <td id=\"T_7d8b74a4_bcbe_11e8_aefe_7933d9accfd0row0_col2\" class=\"data row0 col2\" >8.3</td> \n",
       "        <td id=\"T_7d8b74a4_bcbe_11e8_aefe_7933d9accfd0row0_col3\" class=\"data row0 col3\" >13</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbb9f414ef0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lat.round(decimals=1).style.apply(highlight_far_from_min, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
